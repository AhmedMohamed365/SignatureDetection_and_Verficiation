{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook file insted of main.py to illustrate the results of project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mercy\\anaconda3\\envs\\GANS\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "import inceptionArchitecture\n",
    "import efficient\n",
    "from skimage.feature import hog\n",
    "import bagOfWords\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "\n",
    "import vgg\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def get_files(csv):\n",
    "    data = pd.read_csv(csv)\n",
    "    data[\"label\"][data[\"label\"] == \"real\"] = 0\n",
    "    data[\"label\"][data[\"label\"] == \"forged\"] = 1\n",
    "    person_files = list(data[\"image_name\"])\n",
    "\n",
    "    data[\"label\"].astype(int)\n",
    "    labels = list(data[\"label\"])\n",
    "\n",
    "    return person_files, labels\n",
    "\n",
    "\n",
    "def printMessage(prediction, img):\n",
    "    real_fake = \"\"\n",
    "    if prediction[0].item() == 1:\n",
    "        real_fake = \"forged\"\n",
    "\n",
    "    else:\n",
    "        real_fake = \"real\"\n",
    "\n",
    "    persons = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "    #print(f\"this signature is for person {persons[phaseOnePrediction[0]]} and it's  {real_fake} \")\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_GRAY2RGB))\n",
    "    plt.title(f\"this signature is for person {persons[phaseOnePrediction[0]]} and it's  {real_fake} \")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# TestFiles\n",
    "person_A_fileTest, labels_ATest = get_files(\"personA/Test/personA_SigVerificationTestLabels.csv\")\n",
    "\n",
    "phaseOneModel = pickle.load(open(\"LogisticRegression_mohamed.sav\", \"rb\"))\n",
    "dir = \"SignatureTestSamples\"\n",
    "\n",
    "\n",
    "class sport():\n",
    "    def __init__(self, file_list, dir, labels, mode='train', transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.labels = labels\n",
    "        self.dir = dir\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        if self.mode == 'train':\n",
    "            self.label = self.labels[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(self.dir, self.file_list[idx]))\n",
    "        # convert Image to grayscale\n",
    "        img = img.convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mode == 'train':\n",
    "            img = img.numpy()\n",
    "            return img.astype('float32'), self.labels[idx]\n",
    "        else:\n",
    "            img = img.numpy()\n",
    "            return img.astype('float32'), self.file_list[idx]\n",
    "\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor()\n",
    "\n",
    "])\n",
    "\n",
    "paths = os.listdir(dir)\n",
    "\n",
    "\n",
    "def testModel(testLoader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        samples = 0\n",
    "        for idx, (images, labels) in enumerate(testLoader):\n",
    "            images = images.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(images)\n",
    "            _, preds = outputs.max(1)\n",
    "        return preds\n",
    "\n",
    "\n",
    "def efficienttest(path):\n",
    "    model.eval()\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    with torch.no_grad():\n",
    "        img = Image.open(path)\n",
    "        img = data_transform(img)\n",
    "        outputs = model(img.unsqueeze(0))\n",
    "        _, preds = outputs.max(1)\n",
    "\n",
    "        return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1 st phase : \n",
      "enter 1 to use HOG (classical)\n",
      "enter 2 to use BOW (classical)\n",
      "enter 3 to use deep learning (not classical)\n",
      "       2 nd phase : \n",
      "enter 1 to use 5 models using vgg\n",
      "enter 2 to use siamese\n",
      "distance = tensor([6.7959], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "fake\n",
      "distance = tensor([4.8983], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "real\n",
      "distance = tensor([5.0102], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "fake\n",
      "distance = tensor([2.8150], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "real\n",
      "distance = tensor([3.3555], device='cuda:0', grad_fn=<NormBackward1>)\n",
      "real\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"       1 st phase : \")\n",
    "print(\"enter 1 to use HOG (classical)\")\n",
    "print(\"enter 2 to use BOW (classical)\")\n",
    "print(\"enter 3 to use deep learning (not classical)\")\n",
    "\n",
    "which = input(\"your choice :) :\")\n",
    "while which != '1' and which != '2' and which != '3':\n",
    "    which = input(\"your choice :) :\")\n",
    "\n",
    "print(\"       2 nd phase : \")\n",
    "print(\"enter 1 to use 5 models using vgg\")\n",
    "print(\"enter 2 to use siamese\")\n",
    "which2 = input(\"your choice :) :\")\n",
    "while which2 != '1' and which2 != '2':\n",
    "    which2 = input(\"your choice :) :\")\n",
    "\n",
    "if which2 == '1':\n",
    "    for i in paths:\n",
    "        imgpath = os.path.join(dir, i)\n",
    "        img_data = cv2.imread(imgpath, 0)\n",
    "        img_data = cv2.resize(img_data, (224, 224))\n",
    "\n",
    "        fd, hog_img = hog(img_data, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True,\n",
    "                          multichannel=False)\n",
    "        fd = fd.reshape(1, -1)\n",
    "        phaseOnePrediction = 0\n",
    "        if which == '1':\n",
    "            phaseOnePrediction = phaseOneModel.predict(fd)\n",
    "        elif which == '2':\n",
    "            phaseOnePrediction = bagOfWords.bow(imgpath)\n",
    "        elif which == '5':\n",
    "            phaseOnePrediction = []\n",
    "            model = efficient.efficient_model()\n",
    "            phaseOnePrediction.append(efficienttest(imgpath))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model = vgg.vgg_model(phaseOnePrediction[0], path=\"vgg13bn_models_Weights/\")\n",
    "        imgList = []\n",
    "        imgList.append(i)\n",
    "        # print(i)\n",
    "        person = sport(imgList, dir, [0], \"train\", transform=data_transform)\n",
    "        dataloaderA = DataLoader(person, batch_size=32, shuffle=False)\n",
    "        prediction = testModel(dataloaderA)\n",
    "        printMessage(prediction, img_data)\n",
    "\n",
    "\n",
    "else:\n",
    "\n",
    "    for i in paths:\n",
    "        imgpath = os.path.join(dir, i)\n",
    "        img_data = cv2.imread(imgpath, 0)\n",
    "        img_data = cv2.resize(img_data, (224, 224))\n",
    "\n",
    "        fd, hog_img = hog(img_data, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True,\n",
    "                          multichannel=False)\n",
    "        fd = fd.reshape(1, -1)\n",
    "        phaseOnePrediction = 0\n",
    "        if which == '1':\n",
    "            phaseOnePrediction = phaseOneModel.predict(fd)\n",
    "        elif which == '2':\n",
    "            phaseOnePrediction = bagOfWords.bow(imgpath)\n",
    "        else:\n",
    "            phaseOnePrediction = []\n",
    "            model = efficient.efficient_model()\n",
    "            phaseOnePrediction.append(efficienttest(imgpath))\n",
    "\n",
    "        path = \"ground_truthImages_(SiameseDatabase)\"\n",
    "        ground_truth = 0\n",
    "        if phaseOnePrediction == 0:\n",
    "            ground_truth = (\"personA_41.png\")\n",
    "        if phaseOnePrediction == 1:\n",
    "            ground_truth = (\"personB_41.png\")\n",
    "        if phaseOnePrediction == 2:\n",
    "            ground_truth = (\"personC_41.png\")\n",
    "        if phaseOnePrediction == 3:\n",
    "            ground_truth = (\"personD_40.png\")\n",
    "        if phaseOnePrediction == 4:\n",
    "            ground_truth = (\"personE_41.png\")\n",
    "\n",
    "        # imgpath = os.path.join(dir, i)\n",
    "        # img_data2 = cv2.imread(ground_truth, 0)\n",
    "        # img_data2 = cv2.resize(img_data, (299, 299))\n",
    "        model = inceptionArchitecture.model\n",
    "        model.to(device)\n",
    "        imgList = []\n",
    "        imgList.append(i)\n",
    "        # print(i)\n",
    "        person = sport(imgList, dir, [0], \"train\", transform=data_transform)\n",
    "        person2 = sport([ground_truth], \"ground_truthImages_(SiameseDatabase)\", [0], \"train\", transform=data_transform)\n",
    "        dataloadertest = DataLoader(person, batch_size=32, shuffle=False)\n",
    "        dataloaderground = DataLoader(person2, batch_size=32, shuffle=False)\n",
    "        img1 = None\n",
    "        img2 = None\n",
    "        for imgs, labels in dataloadertest:\n",
    "            img1 = imgs.to(device)\n",
    "        for imgs, labels in dataloaderground:\n",
    "            img2 = imgs.to(device)\n",
    "\n",
    "        output1, output2 = model(img1, img2)\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        print(f\"distance = {euclidean_distance}\")\n",
    "        if euclidean_distance > 5:\n",
    "            print(\"fake\")\n",
    "\n",
    "        else:\n",
    "            print(\"real\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GANS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cee37d227955ca5852ee6f79a051d5fd5922c934dd14fe75b6b475a83e7011ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
